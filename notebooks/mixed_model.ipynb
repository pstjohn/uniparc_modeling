{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 28 14:04:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.116.00   Driver Version: 418.116.00   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    54W / 300W |      0MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000004:05:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    38W / 300W |     10MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000035:03:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    36W / 300W |      0MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000035:04:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    37W / 300W |      0MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.set_visible_devices(gpu_devices[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.model import create_model\n",
    "from bert.losses import ECE, masked_sparse_categorical_crossentropy, masked_sparse_categorical_accuracy\n",
    "from bert.optimization import WarmUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons.optimizers as tfa_optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 768)    18432       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, None, 768)    787200      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 768)    0           embedding[0][0]                  \n",
      "                                                                 position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformer (Transformer)       (None, None, 768)    7087872     add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_1 (Transformer)     (None, None, 768)    7087872     transformer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transformer_2 (Transformer)     (None, None, 768)    7087872     transformer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_3 (Transformer)     (None, None, 768)    7087872     transformer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_4 (Transformer)     (None, None, 768)    7087872     transformer_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_5 (Transformer)     (None, None, 768)    7087872     transformer_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_6 (Transformer)     (None, None, 768)    7087872     transformer_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_7 (Transformer)     (None, None, 768)    7087872     transformer_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_8 (Transformer)     (None, None, 768)    7087872     transformer_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_9 (Transformer)     (None, None, 768)    7087872     transformer_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_10 (Transformer)    (None, None, 768)    7087872     transformer_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_11 (Transformer)    (None, None, 768)    7086336     transformer_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_no_mask (DenseNoMask)     (None, None, 21)     16149       transformer_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 21)     0           dense_no_mask[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 85,874,709\n",
      "Trainable params: 85,874,709\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=1E-4,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=0.0)\n",
    "\n",
    "lr_schedule = WarmUp(\n",
    "    initial_learning_rate=1E-4,\n",
    "    decay_schedule_fn=lr_schedule,\n",
    "    warmup_steps=1000)\n",
    "\n",
    "optimizer = tfa_optimizers.LAMB(\n",
    "    learning_rate=lr_schedule,\n",
    "    weight_decay_rate=0.01,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-6,\n",
    "    exclude_from_weight_decay=['layer_norm', 'bias'])\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = create_model(model_dimension=768,\n",
    "                         transformer_dimension=768 * 4,\n",
    "                         num_attention_heads=768 // 64,\n",
    "                         num_transformer_layers=12,\n",
    "                         vocab_size=24,\n",
    "                         dropout_rate=0.,\n",
    "                         max_relative_position=128,\n",
    "                         max_sequence_length=1024,\n",
    "                         attention_type='absolute')\n",
    "    \n",
    "    model.compile(\n",
    "        loss=masked_sparse_categorical_crossentropy,\n",
    "        metrics=[ECE, masked_sparse_categorical_accuracy],\n",
    "        optimizer=optimizer)\n",
    "\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bert.dataset import create_masked_input_dataset\n",
    "data_path = '/gpfs/alpine/proj-shared/bie108/split_uniref100'\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "training_data = create_masked_input_dataset(\n",
    "    sequence_path=os.path.join(\n",
    "        data_path, 'train_uniref100_split/train_100_*.txt.gz'),\n",
    "    max_sequence_length=16,\n",
    "    fix_sequence_length=True,\n",
    "    batch_size=4,\n",
    "    shard_num_workers=12,\n",
    "    shard_worker_index=0,\n",
    "    masking_freq=.5)\n",
    "\n",
    "valid_data = create_masked_input_dataset(\n",
    "    sequence_path=os.path.join(\n",
    "        data_path, 'train_uniref100_split/train_100_*.txt.gz'),\n",
    "    max_sequence_length=512,\n",
    "    batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10, 32), dtype=int32, numpy=\n",
       " array([[30, 38, 18, 29,  4,  7, 25, 18, 29,  5,  1, 44, 31, 29, 41, 48,\n",
       "         31, 11, 49, 48, 37, 15, 23, 19,  0, 11, 16, 24, 40,  8, 13, 14],\n",
       "        [ 4, 37,  6, 34, 27, 24, 39, 21, 49, 29, 49, 39, 43, 20,  7, 32,\n",
       "         39,  9, 26,  4, 39, 40, 20,  3, 33,  6,  9, 28, 38, 33, 17,  5],\n",
       "        [ 6, 10, 40, 38, 41, 36, 19, 24, 33, 44, 32,  6, 25, 20, 19, 32,\n",
       "         45,  7, 19, 26,  2, 26, 23, 11, 46, 38, 12,  9, 29, 29, 48, 18],\n",
       "        [31, 38, 32, 25, 21, 44, 37, 16,  2, 10, 25, 46, 25, 42, 25, 37,\n",
       "         38, 18, 38, 24, 12, 21, 15, 21, 40,  0, 41, 23, 20, 49, 48, 44],\n",
       "        [23,  8, 25, 18, 15, 28, 18,  0, 35, 17, 42, 29, 34, 12, 12, 15,\n",
       "         24, 17, 14, 17,  7, 14, 19, 49, 38, 42, 37, 16, 44, 21, 30,  9],\n",
       "        [43, 48, 24, 17, 39, 21, 18, 47, 44, 15, 10,  2, 33,  2, 10, 14,\n",
       "         20, 35, 16, 45,  9, 37, 42, 44,  4, 20, 35, 12, 13,  0,  6, 21],\n",
       "        [12,  1, 26, 30, 10, 26, 15, 23, 19, 15, 41,  6, 21, 27, 25, 17,\n",
       "         17, 14, 30, 43, 45, 49, 37, 20,  5, 13, 49, 31, 16,  3, 20,  7],\n",
       "        [46, 47,  1, 27, 17, 45,  1, 31, 26,  0, 40, 21, 32, 11, 43, 35,\n",
       "         36, 25,  9,  5, 41, 21, 41, 26, 39, 41,  2, 34,  5, 48, 11, 42],\n",
       "        [ 2, 25,  7, 26, 47,  2, 31, 48, 28, 31,  1, 12, 41, 41, 27,  3,\n",
       "         22, 33,  2,  9, 47, 20,  9,  0, 48, 33,  4, 37, 10, 14, 39, 41],\n",
       "        [18, 28, 37, 30, 24, 10, 34, 12, 35, 34, 39,  0, 24,  2, 45,  8,\n",
       "          1, 40, 25, 15, 43, 10, 16,  4,  9, 10, 12, 17, 28, 40, 18, 44]],\n",
       "       dtype=int32)>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_generator(lambda: np.random.randint(50, size=(1, 32)),\n",
    "                                    output_types=(tf.int32), output_shapes=(32,)).repeat().batch(10)\n",
    "\n",
    "list(ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.data.Dataset.from_tensors(\n",
    "    [[17, 16,  1,  8, 19,  1, 17,  6,  5,  9, 18,  3, 20, 16, 19, 10],\n",
    "     [ 6, 15,  1,  1,  1,  3, 23,  5, 10, 23,  4, 15, 10, 20, 13,  1],\n",
    "     [ 5, 17,  3, 18, 17,  3,  3, 23, 15,  8,  2, 23, 23,  4, 18,  5],\n",
    "     [ 3, 16,  1,  1, 23,  8,  7,  3,  5, 15, 20, 16, 14, 10,  1,  9]])\n",
    "targets = tf.data.Dataset.from_tensors(\n",
    "    [[ 0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "     [ 0, 15,  0,  0,  0,  0, 15,  0,  0, 17,  0,  0,  0,  0,  0,  0],\n",
    "     [ 0,  0,  0,  0,  0,  0,  0, 11,  0,  0,  0,  9,  4,  0,  0,  0],\n",
    "     [ 0,  0,  0,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
    "\n",
    "dataset = tf.data.Dataset.zip((inputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(4, 16), dtype=int32, numpy=\n",
       "  array([[17, 16,  1,  8, 19,  1, 17,  6,  5,  9, 18,  3, 20, 16, 19, 10],\n",
       "         [ 6, 15,  1,  1,  1,  3, 23,  5, 10, 23,  4, 15, 10, 20, 13,  1],\n",
       "         [ 5, 17,  3, 18, 17,  3,  3, 23, 15,  8,  2, 23, 23,  4, 18,  5],\n",
       "         [ 3, 16,  1,  1, 23,  8,  7,  3,  5, 15, 20, 16, 14, 10,  1,  9]],\n",
       "        dtype=int32)>,\n",
       "  <tf.Tensor: shape=(4, 16), dtype=int32, numpy=\n",
       "  array([[ 0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 15,  0,  0,  0,  0, 15,  0,  0, 17,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0, 11,  0,  0,  0,  9,  4,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "        dtype=int32)>)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 10 steps\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccs/home/pstjohn/.conda/envs/tf21-ibm/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/ccs/home/pstjohn/.conda/envs/tf21-ibm/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 64s 1s/step - loss: 3.1222 - ECE: 22.7023 - masked_sparse_categorical_accuracy: 0.0486 - val_loss: 3.0986 - val_ECE: 22.1688 - val_masked_sparse_categorical_accuracy: 0.0522\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 16s 320ms/step - loss: 3.0646 - ECE: 21.4348 - masked_sparse_categorical_accuracy: 0.0570 - val_loss: 3.0219 - val_ECE: 20.5310 - val_masked_sparse_categorical_accuracy: 0.0658\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 2.9842 - ECE: 19.7770 - masked_sparse_categorical_accuracy: 0.0826 - val_loss: 2.9454 - val_ECE: 19.0194 - val_masked_sparse_categorical_accuracy: 0.1035\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 15s 310ms/step - loss: 2.9201 - ECE: 18.5506 - masked_sparse_categorical_accuracy: 0.1090 - val_loss: 2.8868 - val_ECE: 17.9424 - val_masked_sparse_categorical_accuracy: 0.1208\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 15s 306ms/step - loss: 2.8785 - ECE: 17.7940 - masked_sparse_categorical_accuracy: 0.1311 - val_loss: 2.8586 - val_ECE: 17.4430 - val_masked_sparse_categorical_accuracy: 0.1336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffe385707f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, steps_per_epoch=50, epochs=5,\n",
    "          verbose=1, validation_data=valid_data, validation_steps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
