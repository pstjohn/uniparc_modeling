{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "from bert.dataset import create_masked_input_dataset\n",
    "from bert.layers import (PositionEmbedding, Attention, Transformer, TokenEmbedding, Bias,\n",
    "                         gelu, masked_sparse_categorical_crossentropy, ECE, InverseSquareRootSchedule,\n",
    "                         initializer, Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 1024), (None, 1024)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 22\n",
    "max_seq_len = 1024\n",
    "batchSize = 10\n",
    "\n",
    "def encode(line_tensor):\n",
    "    line = line_tensor.numpy().decode('utf8')\n",
    "\n",
    "    if len(line) > max_seq_len:\n",
    "        offset = np.random.randint(\n",
    "            low=0, high=len(line) - max_seq_len + 1)\n",
    "        line = line[offset:(offset + max_seq_len)]\n",
    "\n",
    "    vocab = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K',\n",
    "             'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', \n",
    "             'W', 'Y']\n",
    "\n",
    "    replacement_dict = {key: i + 2 for i, key in enumerate(vocab)}\n",
    "    return np.asarray([replacement_dict[item] for item in line])\n",
    "\n",
    "def encode_tf(line_tensor):\n",
    "    return tf.py_function(encode, inp=[line_tensor], Tout=[tf.int32,])\n",
    "\n",
    "training_data = create_masked_input_dataset(\n",
    "    encode_fn=encode_tf,\n",
    "    sequence_path='/projects/bpms/pstjohn/uniparc/sequences_train.txt',\n",
    "    max_sequence_length=max_seq_len,\n",
    "    batch_size=batchSize,\n",
    "    buffer_size=1024,\n",
    "    vocab_size=vocab_size,\n",
    "    mask_index=1,\n",
    "    vocab_start=2,\n",
    "    fix_sequence_length=True)\n",
    "\n",
    "training_data.repeat().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_data = create_masked_input_dataset(\n",
    "    encode_fn=encode_tf,\n",
    "    sequence_path='/projects/bpms/pstjohn/uniparc/sequences_valid.txt',\n",
    "    max_sequence_length=max_seq_len,\n",
    "    batch_size=batchSize,\n",
    "    buffer_size=1024,\n",
    "    vocab_size=vocab_size,\n",
    "    mask_index=1,\n",
    "    vocab_start=2,\n",
    "    fix_sequence_length=True)\n",
    "\n",
    "valid_data.repeat().prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_seqs, true_values = next(iter(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3358440, shape=(533,), dtype=int32, numpy=\n",
       "array([ 1,  1,  1,  1,  1,  1,  1,  1, 19,  1,  1, 17,  1,  1,  1, 10,  1,\n",
       "       16, 16,  1,  1,  7,  1,  1,  1,  1,  1,  1,  2,  8, 15,  3,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 14,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1, 11,  1,  1,  7,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  1, 14,  1,  1,  1,\n",
       "        1,  1,  1, 11,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10,  1,\n",
       "        1,  1,  8,  1, 20,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, 16,  5,  1,  1, 12,  1,  1,  1,  1,  2,  1,  1,  1,  1,\n",
       "       17,  1,  1,  1,  1, 17,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  1,\n",
       "        1,  9,  1,  1,  1,  1,  2, 18,  1,  1,  1,  1,  1,  1,  7,  1, 16,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  1, 10, 13,  1,\n",
       "        9,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1, 19,  1,  1,  1,  1,\n",
       "        1,  1,  1, 12,  1,  1,  1, 14,  1,  1,  3, 10,  1, 11,  1,  7,  1,\n",
       "        1,  1,  1, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 14,  1,  1,  4,  1,  1,  1,  1,  1,\n",
       "        4, 16, 10,  1,  1, 15,  1,  1,  1,  1, 11,  3,  1,  1,  1,  1,  9,\n",
       "        1,  1,  1,  1,  1, 14,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  7, 10,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, 15,  1,  1, 10,  1,  1,  1,  1,  7, 21,  1,  1,  1, 14,  1,\n",
       "        1,  1, 13,  1,  1,  1, 19,  1,  1,  1,  1, 14, 10,  3,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  1, 14,  1,  1,  1,  1,  1,  1,  1,  1, 17,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  7,  1,  1, 14,  5, 18,  1,  1,\n",
       "        1, 15,  1,  1,  1, 14, 20, 10,  1,  1,  2,  4,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  7,  2,  7,  1,  1,  1, 21,  1,\n",
       "        6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 11,  1,  2,  1,\n",
       "        6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 17,  6,  1,  4, 19,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 21, 18,  8, 19,  1,  1,  1,  5,  2,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 21,  1, 12,  1,  1,  1,\n",
       "        1, 20,  1,  1, 20,  1,  1,  1,  1,  1,  2,  1,  4,  1,  1,  1,  1,\n",
       "        1,  1,  1, 19,  1,  1,  1,  1,  1, 16,  1,  1,  1,  1, 14,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1], dtype=int32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_seqs[true_values != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1024])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_embedding_4 (TokenEmbeddi multiple             2816        input_10[0][0]                   \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_4 (PositionE (None, None, 128)    131200      input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1024, 128)    0           token_embedding_4[0][0]          \n",
      "                                                                 position_embedding_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_4 (Transformer)     (None, 1024, 128)    198272      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024, 128)    16512       transformer_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bias_4 (Bias)                   (None, 1024, 22)     22          token_embedding_4[1][0]          \n",
      "==================================================================================================\n",
      "Total params: 348,822\n",
      "Trainable params: 348,822\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dimension = 128\n",
    "model_dimension = 128\n",
    "transformer_dimension = 4 * model_dimension\n",
    "num_attention_heads = model_dimension // 64\n",
    "num_transformer_layers = 1\n",
    "\n",
    "dropout_rate = 0.\n",
    "\n",
    "inputs = layers.Input(shape=(max_seq_len,), dtype=tf.int32, batch_size=None)\n",
    "\n",
    "token_embedding_layer = TokenEmbedding(\n",
    "    vocab_size, embedding_dimension, embeddings_initializer=initializer(), mask_zero=True)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "position_embeddings = PositionEmbedding(\n",
    "    max_seq_len + 1, embedding_dimension, embeddings_initializer=initializer(),\n",
    "    mask_zero=True)(inputs)\n",
    "\n",
    "embeddings = layers.Add()([token_embeddings, position_embeddings])\n",
    "# embeddings = Projection(model_dimension, use_residual=False)(embeddings)\n",
    "\n",
    "transformer = Transformer(num_attention_heads, transformer_dimension, dropout=dropout_rate)\n",
    "for i in range(num_transformer_layers):\n",
    "    embeddings = transformer(embeddings)\n",
    "\n",
    "out = layers.Dense(embedding_dimension, activation=gelu, kernel_initializer=initializer())(embeddings)\n",
    "out = token_embedding_layer(out, transpose=True)\n",
    "out = Bias()(out)\n",
    "#out = layers.Softmax()(out)\n",
    "\n",
    "model = tf.keras.Model(inputs, out, name='model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1024, 22])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(masked_seqs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class InverseSquareRootSchedule(Callback):\n",
    "    def __init__(self, \n",
    "                 learning_rate=1E-4,\n",
    "                 warmup_updates=16000):\n",
    "        \"\"\" Implements the linear learning rate warmup and linear learning rate\n",
    "        decay used by google in BERT pretraining \"\"\"\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.warmup_updates = warmup_updates\n",
    "        self.decay_factor = learning_rate * warmup_updates**0.5\n",
    "        self.epoch = 1\n",
    "        self._hist = []\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        global_step = float(logs.get('batch', 1))\n",
    "        \n",
    "        # Still in warmup\n",
    "        if global_step <= self.warmup_updates:\n",
    "            scheduled_lr = self.learning_rate * (\n",
    "                global_step / self.warmup_updates)\n",
    "        \n",
    "        # Linear decay\n",
    "        else:\n",
    "            scheduled_lr = self.decay_factor * global_step**0.5\n",
    "            \n",
    "        self._hist += [(global_step, scheduled_lr)]\n",
    "        K.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        \n",
    "    def on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1E-3\n",
    "warmup_updates = 300\n",
    "\n",
    "# Horovod: add Horovod DistributedOptimizer.\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "true_labels = layers.Input(shape=(None,), dtype=tf.int32, batch_size=None)\n",
    "model.compile(\n",
    "    loss=masked_sparse_categorical_crossentropy,\n",
    "    metrics=[ECE],\n",
    "    target_tensors=true_labels,\n",
    "    experimental_run_tf_function=False,\n",
    "    optimizer=opt)\n",
    "\n",
    "callbacks = [\n",
    "    InverseSquareRootSchedule(learning_rate=learning_rate, warmup_updates=warmup_updates),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 29s 29ms/step - loss: 7.7675 - ECE: inf - val_loss: 2.9061 - val_ECE: 18.2906\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 2.8988 - ECE: 18.1610 - val_loss: 2.8929 - val_ECE: 18.0534\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 2.8996 - ECE: 18.1752 - val_loss: 2.9050 - val_ECE: 18.2762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32ed0e9b90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, steps_per_epoch=1000, epochs=3, verbose=1,\n",
    "          validation_data=valid_data, validation_steps=10,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = callbacks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f32d44895d0>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(a._hist)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 156ms/step - loss: 2.6406 - ECE: 14.0423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6406365633010864, 14.042313]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_data, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"metrics_4/ECE/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"loss_2/bias_1_loss/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    'test_model.h5',\n",
    "    custom_objects={\n",
    "        'PositionEmbedding': PositionEmbedding,\n",
    "        'TokenEmbedding': TokenEmbedding,\n",
    "        'Attention': Attention,\n",
    "        'Transformer': Transformer,\n",
    "        'Projection': Projection,        \n",
    "        'Bias': Bias,\n",
    "        'gelu': gelu,\n",
    "        'masked_sparse_categorical_crossentropy': masked_sparse_categorical_crossentropy,\n",
    "        'ECE': ECE,\n",
    "    })\n",
    "\n",
    "# true_labels = layers.Input(shape=(None,), dtype=tf.int32, batch_size=None)\n",
    "# model.compile(loss=masked_sparse_cross_entropy_loss, target_tensors=true_labels,\n",
    "#               optimizer=tfa.optimizers.AdamW(weight_decay=0.01, learning_rate=1E-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss/bias_1_loss/boolean_mask_1/GatherV2:0\", shape=(None, 22), dtype=float32)\n",
      "Tensor(\"metrics/ECE/boolean_mask_1/GatherV2:0\", shape=(None, 22), dtype=float32)\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 2.6753 - ECE: 14.5317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6753330707550047, 14.531654]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_data, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 10 steps\n",
      "Epoch 1/3\n",
      "Tensor(\"loss/bias_1_loss/boolean_mask_1/GatherV2:0\", shape=(None, 22), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"metrics/ECE/boolean_mask_1/GatherV2:0\", shape=(None, 22), dtype=float32)\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 2.6619 - ECE: 14.3414 - val_loss: 2.6444 - val_ECE: 14.1091\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 2.6664 - ECE: 14.4085 - val_loss: 2.6439 - val_ECE: 14.1070\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 2.6620 - ECE: 14.3416 - val_loss: 2.6658 - val_ECE: 14.3950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33355ea250>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, steps_per_epoch=100, epochs=3, verbose=1,\n",
    "          validation_data=valid_data, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_data = valid_data.map(sp_encode_tf, num_parallel_calls=tf.data.experimental.AUTOTUNE).padded_batch(60, padded_shapes=([512],))\n",
    "# eval_encoded = next(iter(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_predict = model.predict(encoded_data.take(3), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_predict.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
