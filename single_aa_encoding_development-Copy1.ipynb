{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "from bert.dataset import create_masked_input_dataset\n",
    "from bert.layers import (PositionEmbedding, Attention, Transformer, TokenEmbedding, Bias,\n",
    "                         gelu, masked_sparse_categorical_crossentropy, ECE,\n",
    "                         initializer, Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 1024), (None, 1024)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 22\n",
    "max_seq_len = 1024\n",
    "batchSize = 10\n",
    "\n",
    "def encode(line_tensor):\n",
    "    line = line_tensor.numpy().decode('utf8')\n",
    "\n",
    "    if len(line) > max_seq_len:\n",
    "        offset = np.random.randint(\n",
    "            low=0, high=len(line) - max_seq_len + 1)\n",
    "        line = line[offset:(offset + max_seq_len)]\n",
    "\n",
    "    vocab = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K',\n",
    "             'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', \n",
    "             'W', 'Y']\n",
    "\n",
    "    replacement_dict = {key: i + 2 for i, key in enumerate(vocab)}\n",
    "    return np.asarray([replacement_dict[item] for item in line])\n",
    "\n",
    "def encode_tf(line_tensor):\n",
    "    return tf.py_function(encode, inp=[line_tensor], Tout=[tf.int32,])\n",
    "\n",
    "training_data = create_masked_input_dataset(\n",
    "    encode_fn=encode_tf,\n",
    "    sequence_path='/projects/bpms/pstjohn/uniparc/sequences_train.txt',\n",
    "    max_sequence_length=max_seq_len,\n",
    "    batch_size=batchSize,\n",
    "    buffer_size=1024,\n",
    "    vocab_size=vocab_size,\n",
    "    mask_index=1,\n",
    "    vocab_start=2,\n",
    "    fix_sequence_length=True)\n",
    "\n",
    "training_data.repeat().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_data = create_masked_input_dataset(\n",
    "    encode_fn=encode_tf,\n",
    "    sequence_path='/projects/bpms/pstjohn/uniparc/sequences_valid.txt',\n",
    "    max_sequence_length=max_seq_len,\n",
    "    batch_size=batchSize,\n",
    "    buffer_size=1024,\n",
    "    vocab_size=vocab_size,\n",
    "    mask_index=1,\n",
    "    vocab_start=2,\n",
    "    fix_sequence_length=True)\n",
    "\n",
    "valid_data.repeat().prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_seqs, true_values = next(iter(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36558, shape=(512,), dtype=int32, numpy=\n",
       "array([14, 17, 12,  1,  1,  1,  1,  1,  1,  1,  1,  1, 21,  1,  1,  1,  1,\n",
       "        1,  5,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  9,  1,  1,  1,\n",
       "        1, 15,  1,  1, 10,  1, 19, 10,  1,  1,  1,  1,  1, 19,  1,  1,  1,\n",
       "       14, 11,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 11,  1, 15,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 18,  1, 13,  1,  1,  1,  1,  1,  1,\n",
       "        1,  9, 14, 18,  1, 14,  1,  1,  1,  1, 11,  1,  7,  1,  1, 19,  3,\n",
       "        1, 13,  1,  1,  1,  4,  1,  1,  1,  1,  4,  1,  6,  1, 15,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 16,  1,  1,  1,  2,  1,  1,  4,  1,\n",
       "        1,  1, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  5,  8,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  7,  1,  4,\n",
       "        1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1, 15,  1,  1,\n",
       "        1,  1, 11,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 11,  1,\n",
       "       11,  1,  1,  1,  1,  1,  1, 19, 15,  1,  1,  1,  1,  1,  1,  3,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3, 16,  1,  1,  1,  7,  1,\n",
       "        1,  1,  2, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 13,  1,  1,  1,  1,\n",
       "        4,  1,  1,  1, 10,  1,  1,  1,  2,  1,  1,  1, 11,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, 20,  1,  1, 16,  1,  1, 10,  1,\n",
       "        1,  1,  7,  1,  1,  1,  9,  1,  1,  1,  7,  1,  1, 19,  1,  1,  1,\n",
       "        6,  1,  1,  1,  1, 15,  1,  1,  1,  6, 16,  1,  3,  1,  1, 10,  1,\n",
       "        1,  1,  3,  1,  1, 17,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 18, 11,  1,  1, 16,  1,  1,  1,  1,\n",
       "        1,  1,  8,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  7,  1,  1,  1,  1,  1,  6, 11,  1,  1, 16,  1,  1,  1,  1,\n",
       "        1,  4,  1, 15,  1,  1, 12, 12,  1,  1, 12,  1,  1,  1, 19,  1,  1,\n",
       "        1, 21,  1,  1,  1,  5,  1, 18,  1,  1,  1,  1,  1,  1, 11,  1,  1,\n",
       "        1,  1,  1,  1,  1, 10,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10, 20,\n",
       "        1,  1], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_seqs[true_values != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_embedding (TokenEmbedding multiple             2816        input_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, None, 128)    131200      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1024, 128)    0           token_embedding[0][0]            \n",
      "                                                                 position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformer (Transformer)       (None, 1024, 128)    198272      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024, 128)    16512       transformer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bias (Bias)                     (None, 1024, 22)     22          token_embedding[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 348,822\n",
      "Trainable params: 348,822\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dimension = 128\n",
    "model_dimension = 128\n",
    "transformer_dimension = 4 * model_dimension\n",
    "num_attention_heads = model_dimension // 64\n",
    "num_transformer_layers = 1\n",
    "\n",
    "dropout_rate = 0.\n",
    "\n",
    "inputs = layers.Input(shape=(max_seq_len,), dtype=tf.int32, batch_size=None)\n",
    "\n",
    "token_embedding_layer = TokenEmbedding(\n",
    "    vocab_size, embedding_dimension, embeddings_initializer=initializer(), mask_zero=True)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "position_embeddings = PositionEmbedding(\n",
    "    max_seq_len + 1, embedding_dimension, embeddings_initializer=initializer(),\n",
    "    mask_zero=True)(inputs)\n",
    "\n",
    "embeddings = layers.Add()([token_embeddings, position_embeddings])\n",
    "# embeddings = Projection(model_dimension, use_residual=False)(embeddings)\n",
    "\n",
    "transformer = Transformer(num_attention_heads, transformer_dimension, dropout=dropout_rate)\n",
    "for i in range(num_transformer_layers):\n",
    "    embeddings = transformer(embeddings)\n",
    "\n",
    "out = layers.Dense(embedding_dimension, activation=gelu, kernel_initializer=initializer())(embeddings)\n",
    "out = token_embedding_layer(out, transpose=True)\n",
    "out = Bias()(out)\n",
    "#out = layers.Softmax()(out)\n",
    "\n",
    "model = tf.keras.Model(inputs, out, name='model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1024, 22])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(masked_seqs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.python.framework import ops\n",
    "# from tensorflow.python.ops import math_ops\n",
    "# from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "\n",
    "class InverseSquareRootSchedule(Callback):\n",
    "    def __init__(self, \n",
    "                 learning_rate=1E-4,\n",
    "                 warmup_updates=16000):\n",
    "        \"\"\" Implements the linear learning rate warmup and linear learning rate\n",
    "        decay used by google in BERT pretraining \"\"\"\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.warmup_updates = warmup_updates\n",
    "        self.decay_factor = learning_rate * warmup_updates**0.5\n",
    "        self._hist = []\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        \n",
    "        global_step = (\n",
    "            batch + self.current_epoch * self.params['steps'])\n",
    "        \n",
    "        # Still in warmup\n",
    "        if global_step <= self.warmup_updates:\n",
    "            scheduled_lr = self.learning_rate * (\n",
    "                global_step / self.warmup_updates)\n",
    "        \n",
    "        # Linear decay\n",
    "        else:\n",
    "            scheduled_lr = self.decay_factor * global_step**(-0.5)\n",
    "            \n",
    "        self._hist += [(global_step, scheduled_lr)]\n",
    "            \n",
    "        K.set_value(self.model.optimizer.lr, scheduled_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1E-3\n",
    "warmup_updates = 300\n",
    "\n",
    "# Horovod: add Horovod DistributedOptimizer.\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "true_labels = layers.Input(shape=(None,), dtype=tf.int32, batch_size=None)\n",
    "model.compile(\n",
    "    loss=masked_sparse_categorical_crossentropy,\n",
    "    metrics=[ECE],\n",
    "    target_tensors=true_labels,\n",
    "    experimental_run_tf_function=False,\n",
    "    optimizer=opt)\n",
    "\n",
    "callbacks = [\n",
    "    InverseSquareRootSchedule(learning_rate=learning_rate,\n",
    "                              warmup_updates=warmup_updates)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 30s 30ms/step - loss: 2.7395 - ECE: 15.5797 - val_loss: 2.6809 - val_ECE: 14.6183\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 2.6735 - ECE: 14.5073 - val_loss: 2.6722 - val_ECE: 14.5007\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 2.6685 - ECE: 14.4372 - val_loss: 2.6837 - val_ECE: 14.6462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2850537a10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, steps_per_epoch=1000, epochs=3, verbose=1,\n",
    "          validation_data=valid_data, validation_steps=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f27de917e90>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = np.array(callbacks[0]._hist)\n",
    "plt.plot(lrs[:, 0], lrs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_data, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    '/scratch/pstjohn/albert_single_aa_debug_checkpoints/ckpt_1.h5',\n",
    "    custom_objects={\n",
    "        'PositionEmbedding': PositionEmbedding,\n",
    "        'TokenEmbedding': TokenEmbedding,\n",
    "        'Attention': Attention,\n",
    "        'Transformer': Transformer,\n",
    "        'Projection': Projection,        \n",
    "        'Bias': Bias,\n",
    "        'gelu': gelu,\n",
    "        'masked_sparse_categorical_crossentropy': masked_sparse_categorical_crossentropy,\n",
    "        'ECE': ECE,\n",
    "        'InverseSquareRootSchedule': InverseSquareRootSchedule,\n",
    "    })\n",
    "\n",
    "# true_labels = layers.Input(shape=(None,), dtype=tf.int32, batch_size=None)\n",
    "# model.compile(loss=masked_sparse_cross_entropy_loss, target_tensors=true_labels,\n",
    "#               optimizer=tfa.optimizers.AdamW(weight_decay=0.01, learning_rate=1E-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 9s 880ms/step - loss: 2.6666 - ECE: 14.3983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.666582942008972, 14.398306]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_data, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 10 steps\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/100 [>.............................] - ETA: 4:42 - loss: 2.6722 - ECE: 14.4775"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1ede9606c7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(training_data, steps_per_epoch=100, epochs=3, verbose=1,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=valid_data, validation_steps=10)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(training_data, steps_per_epoch=100, epochs=3, verbose=1,\n",
    "          validation_data=valid_data, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_data = valid_data.map(sp_encode_tf, num_parallel_calls=tf.data.experimental.AUTOTUNE).padded_batch(60, padded_shapes=([512],))\n",
    "# eval_encoded = next(iter(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_predict = model.predict(encoded_data.take(3), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_predict.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
